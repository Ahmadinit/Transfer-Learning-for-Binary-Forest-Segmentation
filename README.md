# ğŸŒ² Transfer Learning for Binary Forest Segmentation

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/) [![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/) [![Keras](https://img.shields.io/badge/Keras-2.x-red.svg)](https://keras.io) [![Notebook](https://img.shields.io/badge/Jupyter-Notebook-9C27B0.svg)](https://jupyter.org)

ğŸ’¡ A rigorous, reproducible comparison of training a U-Net segmentation model from scratch versus transfer learning with a pre-trained ResNet50 encoder for binary forest segmentation (forest vs. non-forest). The repo includes an end-to-end notebook, standardized data pipeline, metrics, and visualizations.

## ğŸ§­ Quick Overview

- ğŸŒ³ Goal: Segment forest regions in RGB imagery
- ğŸ§  Models: U-Net (scratch) vs. U-Net + ResNet50 (transfer)
- ğŸ¯ Metrics: IoU, Dice, Accuracy, Precision, Recall, F1
- âš¡ Strategy: Freeze encoder â†’ fine-tune (100 total epochs)
- ğŸ“ˆ Outputs: Metrics table + side-by-side visual comparisons

## ğŸ—ºï¸ Table of Contents

- ğŸ” Problem Statement
- ğŸ¯ Objective
- ğŸ§© Scope & Contributions
- ğŸ—ƒï¸ Dataset
- ğŸ§± Data Pipeline
- ğŸ—ï¸ Model Architecture
- ğŸ”¬ Experimental Design
- ğŸ“ Loss Function
- âš™ï¸ Optimization
- ğŸ“Š Evaluation Metrics
- ğŸ† Results & Analysis
- ğŸ” Reproducibility
- ğŸ“¦ Installation
- ğŸš€ Usage
- ğŸ—‚ï¸ Project Structure
- ğŸ§ª Troubleshooting
- ğŸ“š References

## ğŸ” Problem Statement

Binary segmentation of forest regions in RGB imagery supports environmental monitoring, land-use planning, and remote sensing. Training deep models from scratch is data- and compute-intensive; transfer learning leverages pre-trained features to accelerate convergence and improve accuracy. This project quantifies these trade-offs on a consistent setup.

## ğŸ¯ Objective

Compare two approaches under identical conditions:
- ğŸ§ª U-Net with randomly initialized encoder (scratch)
- ğŸš€ U-Net with ResNet50 encoder pre-trained on ImageNet (transfer)

Evaluate both on:
- ğŸ¯ Effectiveness: IoU, Dice, Accuracy, Precision, Recall, F1
- âš¡ Efficiency: training time and convergence behavior over 100 epochs

## ğŸ§© Scope & Contributions

- ğŸ§° Standardized data pipeline and training protocol for fair comparison
- ğŸ§Šâ†’ğŸ”¥ Phased transfer strategy (freeze, then fine-tune)
- ğŸ“‘ Reproducible metrics and clear tabular reporting
- ğŸ–¼ï¸ Side-by-side visuals for boundary quality and consistency

## ğŸ—ƒï¸ Dataset

- ğŸ“¦ Source: Augmented Forest Segmentation Dataset (Kaggle)
- ğŸ¯ Task: Binary semantic segmentation (forest vs. non-forest)
- ğŸ–¼ï¸ Input: RGB images
- ğŸ­ Output: Binary masks (1 = forest, 0 = background)

Assumptions:
- ğŸ”— Image/mask filenames are paired by stem
- ğŸšï¸ Masks are single-channel binary
- ğŸš« No leakage across train/val/test splits

## ğŸ§± Data Pipeline

Applied consistently across experiments:
- ğŸ“ Resize images/masks to 128Ã—128
- ğŸ›ï¸ Normalize image pixels to [0, 1]
- ğŸ§¼ Ensure masks are binary (threshold if needed)
- ğŸ”€ Split: train/val/test (e.g., 70/15/15)

Expected structure:

```
data/
  train/{images,masks}
  val/{images,masks}
  test/{images,masks}
```

## ğŸ—ï¸ Model Architecture

U-Net decoder + ResNet50 encoder (`segmentation_models`, TF/Keras):

```
ResNet50 Encoder (ImageNet) â†’ multi-scale features
U-Net Decoder â†’ upsampling + skip connections â†’ sigmoid output
```

Why this setup?
- ğŸ§  ResNet50 captures hierarchical features
- ğŸ› ï¸ U-Net decoder restores spatial detail
- ğŸ¯ Sigmoid suits binary masks

## ğŸ”¬ Experimental Design

### A) Scratch Training
- âš™ï¸ Encoder: random init
- ğŸƒ End-to-end training: 100 epochs
- ğŸ¯ Baseline without prior knowledge

### B) Transfer Learning (Phased)
- ğŸ§Š Phase 1 (Epochs 1â€“50): freeze encoder, train decoder
- ğŸ”¥ Phase 2 (Epochs 51â€“100): unfreeze encoder, full fine-tuning

Controls:
- ğŸ§ª Same optimizer and batch size
- ğŸ§ª Identical preprocessing, splits, metrics

## ğŸ“ Loss Function

Composite loss:

L = L_BCE + L_Dice

Dice loss:

L_Dice = 1 âˆ’ (2 Ã— |P âˆ© G|) / (|P| + |G|)

Where P = predicted mask (thresholded), G = ground truth.

## âš™ï¸ Optimization

- ğŸ”§ Optimizer: Adam (SGD optional)
- ğŸšï¸ LR: tuned empirically, recorded in the notebook
- ğŸ§® Batch size: adapted to memory constraints
- â±ï¸ Callbacks: early stopping, checkpoints recommended

## ğŸ“Š Evaluation Metrics

- ğŸ¥‡ IoU = |P âˆ© G| / |P âˆª G|
- ğŸ“ˆ Dice = 1 âˆ’ L_Dice
- âœ… Accuracy
- ğŸ¯ Precision
- ğŸ” Recall
- ğŸ”· F1-Score

## ğŸ† Results & Analysis

### ğŸ“‹ Test Metrics (placeholders)

| Model                | IoU   | Accuracy | Precision | Recall | F1-Score | Train Time |
|----------------------|-------|----------|-----------|--------|----------|------------|
| Scratch (U-Net)      | [TBD] | [TBD]    | [TBD]     | [TBD]  | [TBD]    | [TBD]      |
| Transfer (ResNet50)  | [TBD] | [TBD]    | [TBD]     | [TBD]  | [TBD]    | [TBD]      |

### ğŸ” Discussion

- ğŸŒŸ Transfer typically improves IoU/Dice and boundary adherence
- âš¡ Faster early convergence with frozen encoder
- ğŸ§ª Scratch may overfit or struggle on small structures

### ğŸ–¼ï¸ Visuals

Saved in `results/visualizations/`:
1. ğŸ–¼ï¸ Input image
2. ğŸ­ Ground truth
3. ğŸ”µ Scratch prediction
4. ğŸŸ¢ Transfer prediction

## ğŸ” Reproducibility

- ğŸ² Set seeds (NumPy, TensorFlow)
- ğŸ§¾ Log hyperparameters, LR schedules, splits
- ğŸ’¾ Save checkpoints to `models/`
- ğŸ“¤ Export metrics to `results/metrics.csv`

## ğŸ“¦ Installation

Prereqs:

```bash
Python 3.8+

```

Install:

```bash
pip install -r requirements.txt
```

Note for `segmentation_models`:

```python
import segmentation_models as sm
sm.set_framework('tf.keras')
sm.framework()
```

## ğŸš€ Usage

Run the notebook:

```bash
jupyter notebook "Transfer learning for segmentation.ipynb"
```

Ensure `data/` is structured as described. The notebook trains both setups, logs metrics, and produces visualizations.

## ğŸ—‚ï¸ Project Structure

```
TL-Binary-Forest-Segmentation/
â”œâ”€â”€ Transfer learning for segmentation.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/{images,masks}
â”‚   â”œâ”€â”€ val/{images,masks}
â”‚   â””â”€â”€ test/{images,masks}
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ scratch_model.h5
â”‚   â””â”€â”€ transfer_learning_model.h5
â””â”€â”€ results/
    â”œâ”€â”€ metrics.csv
    â””â”€â”€ visualizations/
```

## ğŸ§ª Troubleshooting

- ğŸ§  OOM: reduce batch size or image size; try mixed precision
- ğŸ“‰ Diverging loss: lower LR; weight decay; verify binary masks
- ğŸªš Poor boundaries: extend fine-tuning; augment with flips/rotations/elastic

## ğŸ“š References

- U-Net â€” https://arxiv.org/abs/1505.04597
- ResNet â€” https://arxiv.org/abs/1512.03385
- Segmentation Models â€” https://github.com/qubvel/segmentation_models

---

If this project helps, â­ star it and share feedback!

